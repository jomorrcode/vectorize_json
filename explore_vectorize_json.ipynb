{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Users can submit a list of attributes for which they want to find the closest matching images.  User requests are captured as nested json.  Each image also has a list of attributes that apply to it, also stored as json.\n",
    "\n",
    "\n",
    "EXAMPLE:\n",
    "\n",
    "{'sex': 'male',\n",
    " 'age': 25,\n",
    " 'skin': {'wrinkles': 1, 'scars': True},\n",
    " 'eyes': 'blue',\n",
    " 'hair': {'colour': 'brown', 'texture': 'wavy', 'length': 'short'},\n",
    " 'emotion': 'happy',\n",
    " 'ears': 'Vulcan',\n",
    " 'nose': 'red'\n",
    " }\n",
    "\n",
    "\n",
    "Comparing nested json objects is very slow.  Calculating Levenshtein distance of an input json object with up to 22 attributes to 1 million existing json objects takes a very long time.  We need to speed this up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assumptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are dealing with 1 million images, each of which has a json file containing a series of attributes which describe the image.\n",
    "\n",
    "Each attribute has a set of possible values.\n",
    "\n",
    "Some attributes may contain nested values.\n",
    "\n",
    "Some attributes are categorical (colour) others boolean (1 or True)\n",
    "\n",
    "Not every image has every attribute.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Idea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flatten the nested json objects and turn them into higher dimension vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Problems to resolve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### * most attributes can be resolved and flattened as strings but age will be an integer\n",
    "    * this is probably easily resolved by just having each age be its own column (i.e. age.24, age.25)\n",
    "    * depends on how Luc has age encoded\n",
    "    * age almost certainly doesn't need to be exact - what does an image of a 26 year old look like vs 25?\n",
    "### * ~~need to figure out how to transform True/False values like {wrinkles: 1}~~\n",
    "### * is there a definitive list of attributes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Key Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import MutableMapping\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from scipy.spatial import distance\n",
    "import scipy.sparse\n",
    "import json\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flatten via generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flattening functions totally stolen: https://www.freecodecamp.org/news/how-to-flatten-a-dictionary-in-python-in-4-different-ways/\n",
    "\n",
    "Using the generator option is much more memory efficient\n",
    "\n",
    "#### sample\\['hair'\\]\\['color'\\] :'brown' becomes 'hair.color.brown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_dict_gen(d, parent_key, sep):\n",
    "    for k, v in d.items():\n",
    "        new_key = parent_key + sep + k if parent_key else k\n",
    "        if isinstance(v, MutableMapping):      # testing if the value is itself a mutable key/value object\n",
    "            yield from flatten_dict(v, new_key, sep=sep).items()\n",
    "        else:\n",
    "            yield new_key, v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_dict(d: MutableMapping, parent_key: str = '', sep: str = '.'):\n",
    "    return dict(flatten_dict_gen(d, parent_key, sep))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert flat json to string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have a flat dictionary, we need to create combine the key/value pairs into a single string.  \n",
    "\n",
    "Need to work around k/v pairs where the value is boolean.  The fact that the pair exists indicates that it was true in the old json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_to_string(in_dict):\n",
    "    dict_string = \" \".join([f\"{k}.{v}\" if v not in [0,1, True, False] else f\"{k}\" for k,v in in_dict.items()])\n",
    "    return dict_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load test file, flatten, convert to string, and vectorize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load json file containing nested json objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.69 s, sys: 688 ms, total: 5.38 s\n",
      "Wall time: 5.36 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with open(\"sample_json_1000000.json\", 'r') as fin:\n",
    "    dict_list = json.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sex': 'female',\n",
       " 'age': 74,\n",
       " 'skin': {'wrinkles': True},\n",
       " 'hair': {'colour': 'blonde', 'length': 'short', 'texture': 'straight'},\n",
       " 'emotion': 'angry',\n",
       " 'ears': 'big',\n",
       " 'eyebrows': 'arched',\n",
       " 'accessories': 'earrings'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flatten json objects and convert to list of strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.37 s, sys: 86.8 ms, total: 8.45 s\n",
      "Wall time: 8.45 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "string_list = []\n",
    "for item in dict_list:\n",
    "    flat = flatten_dict(item)\n",
    "    dict_string = flat_to_string(flat)\n",
    "    #mystring = \" \".join([f\"{k}.{v}\" if v not in [0,1, True, False] else f\"{k}\" for k,v in flat.items()])\n",
    "    string_list.append(dict_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(string_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sex.female age.74 skin.wrinkles hair.colour.blonde hair.length.short hair.texture.straight emotion.angry ears.big eyebrows.arched accessories.earrings'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorize the list of strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(token_pattern='\\S+', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.14 s, sys: 200 ms, total: 6.34 s\n",
      "Wall time: 6.33 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X = vectorizer.fit_transform(string_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1000000x102 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 6205181 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Complete list of attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['accessories.earrings',\n",
       " 'accessories.glasses',\n",
       " 'accessories.hat',\n",
       " 'age.10',\n",
       " 'age.11',\n",
       " 'age.12',\n",
       " 'age.13',\n",
       " 'age.14',\n",
       " 'age.15',\n",
       " 'age.16',\n",
       " 'age.17',\n",
       " 'age.18',\n",
       " 'age.19',\n",
       " 'age.20',\n",
       " 'age.21',\n",
       " 'age.22',\n",
       " 'age.23',\n",
       " 'age.24',\n",
       " 'age.25',\n",
       " 'age.26',\n",
       " 'age.27',\n",
       " 'age.28',\n",
       " 'age.29',\n",
       " 'age.30',\n",
       " 'age.31',\n",
       " 'age.32',\n",
       " 'age.33',\n",
       " 'age.34',\n",
       " 'age.35',\n",
       " 'age.36',\n",
       " 'age.37',\n",
       " 'age.38',\n",
       " 'age.39',\n",
       " 'age.40',\n",
       " 'age.41',\n",
       " 'age.42',\n",
       " 'age.43',\n",
       " 'age.44',\n",
       " 'age.45',\n",
       " 'age.46',\n",
       " 'age.47',\n",
       " 'age.48',\n",
       " 'age.49',\n",
       " 'age.50',\n",
       " 'age.51',\n",
       " 'age.52',\n",
       " 'age.53',\n",
       " 'age.54',\n",
       " 'age.55',\n",
       " 'age.56',\n",
       " 'age.57',\n",
       " 'age.58',\n",
       " 'age.59',\n",
       " 'age.60',\n",
       " 'age.61',\n",
       " 'age.62',\n",
       " 'age.63',\n",
       " 'age.64',\n",
       " 'age.65',\n",
       " 'age.66',\n",
       " 'age.67',\n",
       " 'age.68',\n",
       " 'age.69',\n",
       " 'age.70',\n",
       " 'age.71',\n",
       " 'age.72',\n",
       " 'age.73',\n",
       " 'age.74',\n",
       " 'age.75',\n",
       " 'age.76',\n",
       " 'age.77',\n",
       " 'age.78',\n",
       " 'age.79',\n",
       " 'age.80',\n",
       " 'ears.big',\n",
       " 'ears.droopy',\n",
       " 'ears.huge',\n",
       " 'emotion.angry',\n",
       " 'emotion.happy',\n",
       " 'emotion.sad',\n",
       " 'ethnicity.asian',\n",
       " 'ethnicity.black',\n",
       " 'ethnicity.caucasian',\n",
       " 'ethnicity.hispanic',\n",
       " 'ethnicity.indigenous',\n",
       " 'eyebrows.arched',\n",
       " 'eyebrows.bushy',\n",
       " 'eyebrows.straight',\n",
       " 'hair.colour.black',\n",
       " 'hair.colour.blonde',\n",
       " 'hair.colour.brown',\n",
       " 'hair.colour.gray',\n",
       " 'hair.length.long',\n",
       " 'hair.length.medium',\n",
       " 'hair.length.short',\n",
       " 'hair.texture.curly',\n",
       " 'hair.texture.straight',\n",
       " 'hair.texture.wavy',\n",
       " 'sex.female',\n",
       " 'sex.male',\n",
       " 'skin.scars',\n",
       " 'skin.wrinkles']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the list of attributes to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"attributes.pickle\", \"wb\") as fout:\n",
    "    pickle.dump(Y,fout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the vectorizer for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"vectorizer.pickle\", \"wb\") as fout:\n",
    "    pickle.dump(vectorizer,fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"vectorizer.pickle\", \"rb\") as fin3:\n",
    "    X3 =pickle.load(fin3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find similar vector in array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO:\n",
    "#### This is too expensive.  Instead use the numpy sparse matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get array from vectorized results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_array = X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 102)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 1, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 1, 0, 0]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract row as test vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_index = 375"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_row = x_array[test_index : test_index+1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the nearest matches in the matrix for the test vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 512 ms, sys: 405 ms, total: 917 ms\n",
      "Wall time: 910 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "distances = distance.cdist(test_row, x_array, \"cosine\")[0]\n",
    "five_closest = np.argsort(distances)[:5]  # get N closest matches\n",
    "#closest_match = np.argmin(distances) # this gives index of closest match\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   375, 432047, 553410,  43855, 712138])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "five_closest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.220446049250313e-16"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances[375]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can save the entire 1M record matrix as a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"image_matrix\", 'wb') as fout2:\n",
    "    np.save(fout2, x_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"image_matrix\", 'rb') as fin3:\n",
    "    new_x_array = np.load(fin3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_x_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take an input json file and check it against the 1M record matrix\n",
    "\n",
    "Note: this seems hacky.  There may be a better way to compare the vector of the input json (which will only contain a few columns) against the 102 column rows of the matrix.  This sounds like a question for Sir HEALY, Earl of Embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load list of all attributes from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"attributes.pickle\", \"rb\") as fin2:\n",
    "    attributes = pickle.load(fin2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create dict with all attributes as keys with 0 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes_dict = defaultdict.fromkeys(attributes, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get user input as json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_json = {\n",
    "    'sex' : 'male',\n",
    "    'age' : 55,\n",
    "    'ears' : 'big',\n",
    "    'hair' : {'colour':'blonde' }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flatten user input and convert to string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_input = flatten_dict(input_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_str = flat_to_string(flat_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sex.male age.55 ears.big hair.colour.blonde'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iterate over attributes in the string and change  respective values in attributes_dict to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "for attribute in input_str.split():\n",
    "    attributes_dict[attribute] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(None,\n",
       "            {'accessories.earrings': 0,\n",
       "             'accessories.glasses': 0,\n",
       "             'accessories.hat': 0,\n",
       "             'age.10': 0,\n",
       "             'age.11': 0,\n",
       "             'age.12': 0,\n",
       "             'age.13': 0,\n",
       "             'age.14': 0,\n",
       "             'age.15': 0,\n",
       "             'age.16': 0,\n",
       "             'age.17': 0,\n",
       "             'age.18': 0,\n",
       "             'age.19': 0,\n",
       "             'age.20': 0,\n",
       "             'age.21': 0,\n",
       "             'age.22': 0,\n",
       "             'age.23': 0,\n",
       "             'age.24': 0,\n",
       "             'age.25': 0,\n",
       "             'age.26': 0,\n",
       "             'age.27': 0,\n",
       "             'age.28': 0,\n",
       "             'age.29': 0,\n",
       "             'age.30': 0,\n",
       "             'age.31': 0,\n",
       "             'age.32': 0,\n",
       "             'age.33': 0,\n",
       "             'age.34': 0,\n",
       "             'age.35': 0,\n",
       "             'age.36': 0,\n",
       "             'age.37': 0,\n",
       "             'age.38': 0,\n",
       "             'age.39': 0,\n",
       "             'age.40': 0,\n",
       "             'age.41': 0,\n",
       "             'age.42': 0,\n",
       "             'age.43': 0,\n",
       "             'age.44': 0,\n",
       "             'age.45': 0,\n",
       "             'age.46': 0,\n",
       "             'age.47': 0,\n",
       "             'age.48': 0,\n",
       "             'age.49': 0,\n",
       "             'age.50': 0,\n",
       "             'age.51': 0,\n",
       "             'age.52': 0,\n",
       "             'age.53': 0,\n",
       "             'age.54': 0,\n",
       "             'age.55': 1,\n",
       "             'age.56': 0,\n",
       "             'age.57': 0,\n",
       "             'age.58': 0,\n",
       "             'age.59': 0,\n",
       "             'age.60': 0,\n",
       "             'age.61': 0,\n",
       "             'age.62': 0,\n",
       "             'age.63': 0,\n",
       "             'age.64': 0,\n",
       "             'age.65': 0,\n",
       "             'age.66': 0,\n",
       "             'age.67': 0,\n",
       "             'age.68': 0,\n",
       "             'age.69': 0,\n",
       "             'age.70': 0,\n",
       "             'age.71': 0,\n",
       "             'age.72': 0,\n",
       "             'age.73': 0,\n",
       "             'age.74': 0,\n",
       "             'age.75': 0,\n",
       "             'age.76': 0,\n",
       "             'age.77': 0,\n",
       "             'age.78': 0,\n",
       "             'age.79': 0,\n",
       "             'age.80': 0,\n",
       "             'ears.big': 1,\n",
       "             'ears.droopy': 0,\n",
       "             'ears.huge': 0,\n",
       "             'emotion.angry': 0,\n",
       "             'emotion.happy': 0,\n",
       "             'emotion.sad': 0,\n",
       "             'ethnicity.asian': 0,\n",
       "             'ethnicity.black': 0,\n",
       "             'ethnicity.caucasian': 0,\n",
       "             'ethnicity.hispanic': 0,\n",
       "             'ethnicity.indigenous': 0,\n",
       "             'eyebrows.arched': 0,\n",
       "             'eyebrows.bushy': 0,\n",
       "             'eyebrows.straight': 0,\n",
       "             'hair.colour.black': 0,\n",
       "             'hair.colour.blonde': 1,\n",
       "             'hair.colour.brown': 0,\n",
       "             'hair.colour.gray': 0,\n",
       "             'hair.length.long': 0,\n",
       "             'hair.length.medium': 0,\n",
       "             'hair.length.short': 0,\n",
       "             'hair.texture.curly': 0,\n",
       "             'hair.texture.straight': 0,\n",
       "             'hair.texture.wavy': 0,\n",
       "             'sex.female': 0,\n",
       "             'sex.male': 1,\n",
       "             'skin.scars': 0,\n",
       "             'skin.wrinkles': 0})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributes_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a 2D array of the values in the attributes_dict\n",
    "\n",
    "As mentioned, this is a real hack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_vector = np.array([list(attributes_dict.values())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_vector[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 514 ms, sys: 404 ms, total: 918 ms\n",
      "Wall time: 917 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "input_distances = distance.cdist(input_vector, x_array, \"cosine\")[0]\n",
    "five_closest = np.argsort(input_distances)[:5]  # get N closest matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([849770, 356286, 882888, 572881, 753306])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "five_closest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10557280900008414"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_distances[849770]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_array[771755]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the sparse matrix\n",
    "This only has to be redone if the image database and the descriptive json objects change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.sparse.save_npz('database_matrix.npz', X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can reload the matrix with:\n",
    "# X = scipy.sparse.load_npz('database_matrix.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data",
   "language": "python",
   "name": "data"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

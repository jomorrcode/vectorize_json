{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6cb3b92-d74f-4dad-9034-e073197992be",
   "metadata": {},
   "source": [
    "# Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660d491f-2495-423d-8561-2df633925120",
   "metadata": {},
   "source": [
    "Users can submit a list of attributes for which they want to find the closest matching images.  User requests are captured as nested json.  Each image also has a list of attributes that apply to it, also stored as json.\n",
    "\n",
    "\n",
    "EXAMPLE:\n",
    "\n",
    "{'sex': 'male',\n",
    " 'age': 25,\n",
    " 'skin': {'wrinkles': 1, 'scars': True},\n",
    " 'eyes': 'blue',\n",
    " 'hair': {'colour': 'brown', 'texture': 'wavy', 'length': 'short'},\n",
    " 'emotion': 'happy',\n",
    " 'ears': 'Vulcan',\n",
    " 'nose': 'red'\n",
    " }\n",
    "\n",
    "\n",
    "Comparing nested json objects is very slow.  Calculating Levenshtein distance of an input json object with up to 22 attributes to 1 million existing json objects takes a very long time.  We need to speed this up."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991b136b",
   "metadata": {},
   "source": [
    "# Assumptions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91f04a9",
   "metadata": {},
   "source": [
    "We are dealing with 1 million images, each of which has a json file containing a series of attributes which describe the image.\n",
    "\n",
    "Each attribute has a set of possible values.\n",
    "\n",
    "Some attributes may contain nested values.\n",
    "\n",
    "Some attributes are categorical (colour) others boolean (1 or True)\n",
    "\n",
    "Not every image has every attribute.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fff6c35-b9f2-406d-bb37-c44976599184",
   "metadata": {},
   "source": [
    "# Idea"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e1b085-1ebb-4e33-aaa9-a8a9b614758e",
   "metadata": {},
   "source": [
    "Flatten the nested json objects and turn them into higher dimension vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f4a430-fdad-42bf-a31c-dd41065c06c2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Problems to resolve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204dfffc-3311-4c5f-93ba-714dbc85249e",
   "metadata": {},
   "source": [
    "### * most attributes can be resolved and flattened as strings but age will be an integer\n",
    "    * this is probably easily resolved by just having each age be its own column (i.e. age.24, age.25)\n",
    "    * depends on how Luc has age encoded\n",
    "    * age almost certainly doesn't need to be exact - what does an image of a 26 year old look like vs 25?\n",
    "### * ~~need to figure out how to transform True/False values like {wrinkles: 1}~~\n",
    "### * is there a definitive list of attributes?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96e6aa9-0cf7-4d95-80be-bfc618f9f36e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Key Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d98c0422-0f00-41aa-8232-7d1e8fa2792e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import MutableMapping\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from scipy.spatial import distance\n",
    "import json\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f63eb2-2a04-4c5b-bcb5-fb0093d41c2b",
   "metadata": {},
   "source": [
    "### Flatten via generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a564bb6-2885-40cf-b603-8c2cd5f2f444",
   "metadata": {},
   "source": [
    "Flattening functions totally stolen: https://www.freecodecamp.org/news/how-to-flatten-a-dictionary-in-python-in-4-different-ways/\n",
    "\n",
    "Using the generator option is much more memory efficient\n",
    "\n",
    "#### sample\\['hair'\\]\\['color'\\] :'brown' becomes 'hair.color.brown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7afd0ce-0d09-493e-b590-938b78c3267c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_dict_gen(d, parent_key, sep):\n",
    "    for k, v in d.items():\n",
    "        new_key = parent_key + sep + k if parent_key else k\n",
    "        if isinstance(v, MutableMapping):      # testing if the value is itself a mutable key/value object\n",
    "            yield from flatten_dict(v, new_key, sep=sep).items()\n",
    "        else:\n",
    "            yield new_key, v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bc05465-a27c-40e9-a05f-34e50c22b1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_dict(d: MutableMapping, parent_key: str = '', sep: str = '.'):\n",
    "    return dict(flatten_dict_gen(d, parent_key, sep))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce299275-40a3-4740-954f-d5f634d588e5",
   "metadata": {},
   "source": [
    "### Convert flat json to string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a30267e-6bee-4c70-b95a-9e3e55113dc3",
   "metadata": {},
   "source": [
    "Once we have a flat dictionary, we need to create combine the key/value pairs into a single string.  \n",
    "\n",
    "Need to work around k/v pairs where the value is boolean.  The fact that the pair exists indicates that it was true in the old json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb631599-14bc-42ac-ae97-9e42902aaf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_to_string(in_dict):\n",
    "    as_str = \" \".join([f\"{k}.{v}\" if v not in [0,1, True, False] else f\"{k}\" for k,v in in_dict.items()])\n",
    "    return as_str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b21241b-af8d-401e-8355-ca5e89a87439",
   "metadata": {},
   "source": [
    "# Load test file, flatten, convert to string, and vectorize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec50933d",
   "metadata": {},
   "source": [
    "#### Load json file containing nested json objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "747efc2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.59 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with open(\"sample_json_1000000.json\", 'r') as fin:\n",
    "    dict_list = json.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5db27fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dict_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb10e42",
   "metadata": {},
   "source": [
    "#### Flatten json objects and convert to list of strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5ce452b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9.24 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "string_list = []\n",
    "for item in dict_list:\n",
    "    flat = flatten_dict(item)\n",
    "    as_str = flat_to_string(flat)\n",
    "    #mystring = \" \".join([f\"{k}.{v}\" if v not in [0,1, True, False] else f\"{k}\" for k,v in flat.items()])\n",
    "    string_list.append(as_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f40372ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sex': 'female',\n",
       " 'age': 73,\n",
       " 'hair.colour': 'gray',\n",
       " 'hair.length': 'medium',\n",
       " 'ethnicity': 'asian',\n",
       " 'eyebrows': 'bushy',\n",
       " 'accessories': 'earrings'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8f17eb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sex.female age.73 hair.colour.gray hair.length.medium ethnicity.asian eyebrows.bushy accessories.earrings'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "as_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57af653b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(string_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3da00b9",
   "metadata": {},
   "source": [
    "#### Vectorize the list of strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ee5e061",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(token_pattern='\\S+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e8697c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5.97 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X = vectorizer.fit_transform(string_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf5a214a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "413ad2b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088f09c8",
   "metadata": {},
   "source": [
    "#### Complete list of attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70bd2f5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['accessories.earrings',\n",
       " 'accessories.glasses',\n",
       " 'accessories.hat',\n",
       " 'age.10',\n",
       " 'age.11',\n",
       " 'age.12',\n",
       " 'age.13',\n",
       " 'age.14',\n",
       " 'age.15',\n",
       " 'age.16',\n",
       " 'age.17',\n",
       " 'age.18',\n",
       " 'age.19',\n",
       " 'age.20',\n",
       " 'age.21',\n",
       " 'age.22',\n",
       " 'age.23',\n",
       " 'age.24',\n",
       " 'age.25',\n",
       " 'age.26',\n",
       " 'age.27',\n",
       " 'age.28',\n",
       " 'age.29',\n",
       " 'age.30',\n",
       " 'age.31',\n",
       " 'age.32',\n",
       " 'age.33',\n",
       " 'age.34',\n",
       " 'age.35',\n",
       " 'age.36',\n",
       " 'age.37',\n",
       " 'age.38',\n",
       " 'age.39',\n",
       " 'age.40',\n",
       " 'age.41',\n",
       " 'age.42',\n",
       " 'age.43',\n",
       " 'age.44',\n",
       " 'age.45',\n",
       " 'age.46',\n",
       " 'age.47',\n",
       " 'age.48',\n",
       " 'age.49',\n",
       " 'age.50',\n",
       " 'age.51',\n",
       " 'age.52',\n",
       " 'age.53',\n",
       " 'age.54',\n",
       " 'age.55',\n",
       " 'age.56',\n",
       " 'age.57',\n",
       " 'age.58',\n",
       " 'age.59',\n",
       " 'age.60',\n",
       " 'age.61',\n",
       " 'age.62',\n",
       " 'age.63',\n",
       " 'age.64',\n",
       " 'age.65',\n",
       " 'age.66',\n",
       " 'age.67',\n",
       " 'age.68',\n",
       " 'age.69',\n",
       " 'age.70',\n",
       " 'age.71',\n",
       " 'age.72',\n",
       " 'age.73',\n",
       " 'age.74',\n",
       " 'age.75',\n",
       " 'age.76',\n",
       " 'age.77',\n",
       " 'age.78',\n",
       " 'age.79',\n",
       " 'age.80',\n",
       " 'ears.big',\n",
       " 'ears.droopy',\n",
       " 'ears.huge',\n",
       " 'emotion.angry',\n",
       " 'emotion.happy',\n",
       " 'emotion.sad',\n",
       " 'ethnicity.asian',\n",
       " 'ethnicity.black',\n",
       " 'ethnicity.caucasian',\n",
       " 'ethnicity.hispanic',\n",
       " 'ethnicity.indigenous',\n",
       " 'eyebrows.arched',\n",
       " 'eyebrows.bushy',\n",
       " 'eyebrows.straight',\n",
       " 'hair.colour.black',\n",
       " 'hair.colour.blonde',\n",
       " 'hair.colour.brown',\n",
       " 'hair.colour.gray',\n",
       " 'hair.length.long',\n",
       " 'hair.length.medium',\n",
       " 'hair.length.short',\n",
       " 'hair.texture.curly',\n",
       " 'hair.texture.straight',\n",
       " 'hair.texture.wavy',\n",
       " 'sex.female',\n",
       " 'sex.male',\n",
       " 'skin.scars',\n",
       " 'skin.wrinkles']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42cf199d",
   "metadata": {},
   "source": [
    "#### Save the list of attributes to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc31535f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"attributes.pickle\", \"wb\") as fout:\n",
    "    pickle.dump(Y,fout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646af3c6",
   "metadata": {},
   "source": [
    "# Find similar vector in array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5e7b05",
   "metadata": {},
   "source": [
    "### Get array from vectorized results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1dde740e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_array = X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "46b7eb5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 102)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae04ccc",
   "metadata": {},
   "source": [
    "### Extract row as test vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "175bab45",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_index = 375"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6ff32832",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_row = x_array[test_index : test_index+1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "07d74c3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "        1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afad25e4",
   "metadata": {},
   "source": [
    "## Find the nearest matches in the matrix for the test vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "33a32416",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "daddc7d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 310 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "distances = distance.cdist(test_row, x_array, \"cosine\")[0]\n",
    "five_closest = np.argsort(distances)[:5]  # get N closest matches\n",
    "#closest_match = np.argmin(distances) # this gives index of closest match\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2b4e7934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   375, 719164, 698364, 221157, 226679], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "five_closest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "78f229d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances[375]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec9a425",
   "metadata": {},
   "source": [
    "### You can save the entire 1M record matrix as a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "812151a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 102)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "97e154d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"image_matrix\", 'wb') as fout2:\n",
    "    np.save(fout2, x_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f1e0c354",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"image_matrix\", 'rb') as fin3:\n",
    "    new_x_array = np.load(fin3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7887b2f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 102)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_x_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e17400",
   "metadata": {},
   "source": [
    "## Take an input json file and check it against the 1M record matrix\n",
    "\n",
    "Note: this seems hacky.  There may be a better way to compare the vector of the input json (which will only contain a few columns) against the 102 column rows of the matrix.  This sounds like a question for Sir HEALY, Earl of Embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "776ba7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf284a21",
   "metadata": {},
   "source": [
    "#### Load list of all attributes from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a19e7012",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"attributes.pickle\", \"rb\") as fin2:\n",
    "    attributes = pickle.load(fin2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f116664",
   "metadata": {},
   "source": [
    "#### Create dict with all attributes as keys with 0 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2207ecf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes_dict = defaultdict.fromkeys(attributes, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119b5049",
   "metadata": {},
   "source": [
    "#### Get user input as json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "932336b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_json = {\n",
    "    'sex' : 'male',\n",
    "    'age' : 55,\n",
    "    'ears' : 'big',\n",
    "    'hair' : {'colour':'blonde' }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33b8b72",
   "metadata": {},
   "source": [
    "#### Flatten user input and convert to string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a891f216",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_input = flatten_dict(input_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "14948f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_str = flat_to_string(flat_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "489a6d77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sex.male age.55 ears.big hair.colour.blonde'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a958c239",
   "metadata": {},
   "source": [
    "#### Iterate over attributes in the string and change  respective values in attributes_dict to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e3e272a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for attribute in input_str.split():\n",
    "    attributes_dict[attribute] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a8d7f884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(None,\n",
       "            {'accessories.earrings': 0,\n",
       "             'accessories.glasses': 0,\n",
       "             'accessories.hat': 0,\n",
       "             'age.10': 0,\n",
       "             'age.11': 0,\n",
       "             'age.12': 0,\n",
       "             'age.13': 0,\n",
       "             'age.14': 0,\n",
       "             'age.15': 0,\n",
       "             'age.16': 0,\n",
       "             'age.17': 0,\n",
       "             'age.18': 0,\n",
       "             'age.19': 0,\n",
       "             'age.20': 0,\n",
       "             'age.21': 0,\n",
       "             'age.22': 0,\n",
       "             'age.23': 0,\n",
       "             'age.24': 0,\n",
       "             'age.25': 0,\n",
       "             'age.26': 0,\n",
       "             'age.27': 0,\n",
       "             'age.28': 0,\n",
       "             'age.29': 0,\n",
       "             'age.30': 0,\n",
       "             'age.31': 0,\n",
       "             'age.32': 0,\n",
       "             'age.33': 0,\n",
       "             'age.34': 0,\n",
       "             'age.35': 0,\n",
       "             'age.36': 0,\n",
       "             'age.37': 0,\n",
       "             'age.38': 0,\n",
       "             'age.39': 0,\n",
       "             'age.40': 0,\n",
       "             'age.41': 0,\n",
       "             'age.42': 0,\n",
       "             'age.43': 0,\n",
       "             'age.44': 0,\n",
       "             'age.45': 0,\n",
       "             'age.46': 0,\n",
       "             'age.47': 0,\n",
       "             'age.48': 0,\n",
       "             'age.49': 0,\n",
       "             'age.50': 0,\n",
       "             'age.51': 0,\n",
       "             'age.52': 0,\n",
       "             'age.53': 0,\n",
       "             'age.54': 0,\n",
       "             'age.55': 1,\n",
       "             'age.56': 0,\n",
       "             'age.57': 0,\n",
       "             'age.58': 0,\n",
       "             'age.59': 0,\n",
       "             'age.60': 0,\n",
       "             'age.61': 0,\n",
       "             'age.62': 0,\n",
       "             'age.63': 0,\n",
       "             'age.64': 0,\n",
       "             'age.65': 0,\n",
       "             'age.66': 0,\n",
       "             'age.67': 0,\n",
       "             'age.68': 0,\n",
       "             'age.69': 0,\n",
       "             'age.70': 0,\n",
       "             'age.71': 0,\n",
       "             'age.72': 0,\n",
       "             'age.73': 0,\n",
       "             'age.74': 0,\n",
       "             'age.75': 0,\n",
       "             'age.76': 0,\n",
       "             'age.77': 0,\n",
       "             'age.78': 0,\n",
       "             'age.79': 0,\n",
       "             'age.80': 0,\n",
       "             'ears.big': 1,\n",
       "             'ears.droopy': 0,\n",
       "             'ears.huge': 0,\n",
       "             'emotion.angry': 0,\n",
       "             'emotion.happy': 0,\n",
       "             'emotion.sad': 0,\n",
       "             'ethnicity.asian': 0,\n",
       "             'ethnicity.black': 0,\n",
       "             'ethnicity.caucasian': 0,\n",
       "             'ethnicity.hispanic': 0,\n",
       "             'ethnicity.indigenous': 0,\n",
       "             'eyebrows.arched': 0,\n",
       "             'eyebrows.bushy': 0,\n",
       "             'eyebrows.straight': 0,\n",
       "             'hair.colour.black': 0,\n",
       "             'hair.colour.blonde': 1,\n",
       "             'hair.colour.brown': 0,\n",
       "             'hair.colour.gray': 0,\n",
       "             'hair.length.long': 0,\n",
       "             'hair.length.medium': 0,\n",
       "             'hair.length.short': 0,\n",
       "             'hair.texture.curly': 0,\n",
       "             'hair.texture.straight': 0,\n",
       "             'hair.texture.wavy': 0,\n",
       "             'sex.female': 0,\n",
       "             'sex.male': 1,\n",
       "             'skin.scars': 0,\n",
       "             'skin.wrinkles': 0})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributes_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1a8f8b",
   "metadata": {},
   "source": [
    "#### Create a 2D array of the values in the attributes_dict\n",
    "\n",
    "As mentioned, this is a real hack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9ff6594e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_vector = np.array([list(attributes_dict.values())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a399de37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_vector[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2428c170",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_distances = distance.cdist(input_vector, x_array, \"cosine\")[0]\n",
    "five_closest = np.argsort(input_distances)[:5]  # get N closest matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0741986f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([771755, 687823, 268132, 355174, 895159], dtype=int64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "five_closest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f447e2a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10557280900008414"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_distances[771755]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d8f5bef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_array[771755]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95836ed9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "image_gen",
   "language": "python",
   "name": "image_gen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
